{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xloem/techsketball/blob/wip/model_import_sketch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH1Ld_vd9wyx",
        "outputId": "f89f82d1-bc3b-45ba-d04e-77ca2c7805d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.7/dist-packages (0.5.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.10.0+cu111)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.7/dist-packages (from deepspeed) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.62.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.10.2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Requirement already satisfied: triton==1.0.0 in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.7/dist-packages (from deepspeed) (8.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->deepspeed) (3.10.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax) (0.1.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.19.5)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: jax>=0.2.21 in /usr/local/lib/python3.7/dist-packages (from flax) (0.2.25)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.2.21->flax) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.71+cuda111)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.6)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (2.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "fatal: destination path 'techsketball' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "\n",
        "import jax\n",
        "\n",
        "starting_model_path = 'baffo32/pyc2py_alpha' #'t5-base'#'t5-small'#'bigscience/T0pp'\n",
        "\n",
        "input_width = 512\n",
        "# these are not t5 parameters?\n",
        "train_batch_size = 19 # small for notebook\n",
        "per_device_batch_size = train_batch_size // jax.device_count()\n",
        "num_epochs = 2\n",
        "training_seed = 0\n",
        "learning_rate = 3e-4\n",
        "logging_steps = 1\n",
        "\n",
        "\n",
        "#!pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "!pip3 install deepspeed\n",
        "!pip3 install transformers\n",
        "!pip3 install flax\n",
        "!pip3 install sentencepiece\n",
        "!git clone https://github.com/xloem/techsketball && ln -s techsketball/* ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTGBjrXoX2eS",
        "outputId": "d7c8ff00-ac6c-40c9-d7ce-104106235be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 18 03:02:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    34W / 250W |  14799MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[GpuDevice(id=0, process_index=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import jax.tools.colab_tpu\n",
        "import jaxlib\n",
        "import os\n",
        "try:\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    jax.tools.colab_tpu.setup_tpu()\n",
        "  jaxlib.xla_extension.tpu_client()\n",
        "  backend = 'tpu'\n",
        "except:\n",
        "  try:\n",
        "    jaxlib.xla_extension.gpu_client()\n",
        "    backend = 'gpu'\n",
        "  except:\n",
        "    backend = 'cpu'\n",
        "import tensorflow as tf\n",
        "!nvidia-smi\n",
        "jax.local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qhJhFJfQAOXG"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, FlaxT5ForConditionalGeneration \n",
        "import huggingface_hub\n",
        "#repo = huggingface_hub.Repository('local_model', clone_from='hub_model_id')\n",
        "try:\n",
        "    tokenizer = T5Tokenizer.from_pretrained('local_model')\n",
        "except:\n",
        "    tokenizer = T5Tokenizer.from_pretrained(starting_model_path)\n",
        "try:\n",
        "    model = FlaxT5ForConditionalGeneration.from_pretrained('local_model')\n",
        "except:\n",
        "    model = FlaxT5ForConditionalGeneration.from_pretrained(starting_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mZqc_JNhixjS"
      },
      "outputs": [],
      "source": [
        "# before data is generated we can import libraries to generate it from\n",
        "import jax, jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import flax\n",
        "import flax.training.common_utils\n",
        "import flax.training.train_state\n",
        "import tqdm\n",
        "import time\n",
        "import os\n",
        "# ...\n",
        "import transformers\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnyDTDt_f1fE",
        "outputId": "a57a19ba-5ed8-45c4-fe1d-e36f2effe610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting training data ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py:171: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  \"torch.distributed.reduce_op is deprecated, please use \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import find_pycode\n",
        "print('getting training data ...')\n",
        "tokenizerpfx = starting_model_path.replace('/','_') + '.'\n",
        "find_pycode.write_files('example.', tokenizerpfx, 512, tokenizer, 512, globals(), skip_if_exists = True, train_tokenizer = True, tokenize_binary = True)\n",
        "tokenizer.save_pretrained('local_model')\n",
        "# repo.push_to_hub(commit_message=f'commit-message', blocking=False)\n",
        "train_data = find_pycode.read_files('example.', tokenizerpfx, 512, 512, tokenize_binary = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6qTNv8oZwbGS"
      },
      "outputs": [],
      "source": [
        "#from tokenizers import ByteLevelBPETokenizer\n",
        "#tokenizer = ByteLevelBPETokenizer()\n",
        "#tokenizer.train_from_iterator((str for bytes, str in data_tuples), vocab_size=model.config.vocab_size, min_frequency=2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CxCgcJ0dzQY_",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sdJ1Ek3-_j37"
      },
      "outputs": [],
      "source": [
        "#import deepspeed\n",
        "#cmd_args = None\n",
        "#model_engine, optimizer, _, _ = deepspeed.initialize(args=cmd_args,\n",
        "#                                                     model=model,\n",
        "#                                                     model_parameters=params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nTQyR1KO4Sbv"
      },
      "outputs": [],
      "source": [
        "num_train_steps = len(train_data['input_ids']) // train_batch_size * num_epochs\n",
        "\n",
        "rng = jax.random.PRNGKey(training_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gD_cvz5MebpC"
      },
      "outputs": [],
      "source": [
        "def batch_from_indices(dataset : dict, indices):\n",
        "  #print(dataset['input_ids'].shape, indices.shape)\n",
        "  result = {\n",
        "      key : jnp.stack(data[indices,:])\n",
        "      for key, data in dataset.items()\n",
        "  }\n",
        "  # this change could be already put in the dataset passed by the function that produces it\n",
        "  result['labels'] = result['decoder_input_ids']\n",
        "  result['decoder_input_ids'] = np.asarray(transformers.models.t5.modeling_flax_t5.shift_tokens_right(result['labels'], tokenizer.pad_token_id, model.config.decoder_start_token_id))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m58ESSevKp6P",
        "lines_to_next_cell": 2,
        "outputId": "b414fe77-415d-443f-ef75-1f6a0d54c784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiling prim_fun (140680119478784) for args ().\n",
            "WARNING:absl:Compiling _shuffle (140695756273936) for args (ShapedArray(uint32[2]), ShapedArray(int32[22391])).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing initial batch to compile train step ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiling prim_fun (140703134345968) for args (ShapedArray(int32[22391]), ShapedArray(int32[1])).\n",
            "WARNING:absl:Compiling train_step (140680118331744) for 1 devices with args (ShapedArray(int32[1]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,32,12]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,32,12]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,32128,768]), ShapedArray(int32[1]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,32,12]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,32,12]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,32128,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,32,12]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,32,12]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768,3072]), ShapedArray(float32[1,3072,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,768]), ShapedArray(float32[1,32128,768]), ShapedArray(int32[1]), ShapedArray(uint8[1,19,512]), ShapedArray(uint8[1,19,512]), ShapedArray(uint16[1,19,512]), ShapedArray(uint16[1,19,512]), ShapedArray(uint16[1,19,512]), ShapedArray(uint32[1,2])). (num_replicas=1 num_partitions=1)\n",
            "WARNING:absl:Compiling _multi_slice (140680149811024) for args (ShapedArray(uint8[1,19,512]),).\n",
            "WARNING:absl:Compiling _multi_slice (140680149810464) for args (ShapedArray(uint16[1,19,512]),).\n",
            "WARNING:absl:Compiling _multi_slice (140680152513984) for args (ShapedArray(uint32[1,2]),).\n",
            "WARNING:absl:Compiling _mean (140680295601328) for args (ShapedArray(float32[]),).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.  First loss was 6.166926\n"
          ]
        }
      ],
      "source": [
        "# these are not t5 parameters?\n",
        "linear_decay_lr_schedule_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps)\n",
        "adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=0.9, b2=0.98, eps=1e-8, weight_decay=0.01)\n",
        "state = flax.training.train_state.TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw)\n",
        "\n",
        "jax.config.update('jax_log_compiles', True)\n",
        "\n",
        "\n",
        "# from run_t5_mlm_flax.py\n",
        "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n",
        "\n",
        "# Define gradient update step fn\n",
        "def train_step(state, batch, dropout_rng):#input_ids, attention_mask, labels, decoder_input_ids, decoder_attention_mask, dropout_rng):\n",
        "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
        "    def loss_fn(params):\n",
        "        labels = batch.pop('labels')\n",
        "\n",
        "        #logits = state.apply_fn(\n",
        "        #    input_ids = input_ids,\n",
        "        #    attention_mask = attention_mask,\n",
        "        #    decoder_input_ids = decoder_input_ids,\n",
        "        #    decoder_attention_mask = decoder_attention_mask,\n",
        "        #    params = params,\n",
        "        #    dropout_rng = dropout_rng,\n",
        "        #    train = True\n",
        "        #).logits\n",
        "        logits = state.apply_fn(**batch, params = params, dropout_rng = dropout_rng, train = True).logits\n",
        "        #print(logits.shape)\n",
        "        #assert len(logits[-1]) == tokenizer.vocab_size\n",
        "        #logits = logits[0]\n",
        "\n",
        "        # logits, labels, padding_mask=batch['decoder_attention_mask', label_smoothing_factor=0]\n",
        "        # compute loss\n",
        "        loss = optax.softmax_cross_entropy(logits, flax.training.common_utils.onehot(labels, logits.shape[-1]))\n",
        "        padding_mask = batch['decoder_attention_mask']\n",
        "        loss = (loss * padding_mask).sum() / padding_mask.sum()\n",
        "\n",
        "        #loss = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True).loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    grad_fn = jax.value_and_grad(loss_fn)\n",
        "    loss, grad = grad_fn(state.params)\n",
        "    grad = jax.lax.pmean(grad, \"batch\")\n",
        "    new_state = state.apply_gradients(grads=grad)\n",
        "\n",
        "    metrics = jax.lax.pmean(\n",
        "        {\"loss\": loss, \"learning_rate\": linear_decay_lr_schedule_fn(state.step)}, axis_name=\"batch\"\n",
        "    )\n",
        "\n",
        "    return new_state, metrics, new_dropout_rng\n",
        "\n",
        "# Create parallel version of the train step\n",
        "p_train_step = jax.pmap(train_step, 'batch', donate_argnums=(0,), backend=backend)\n",
        "\n",
        "# Replicate the train state on each device\n",
        "state = flax.jax_utils.replicate(state)\n",
        "\n",
        "print('Performing initial batch to compile train step ...')\n",
        "rng, input_rng = jax.random.split(rng)\n",
        "num_train_samples = len(train_data['input_ids'])\n",
        "train_samples_idx = jax.random.permutation(input_rng, jnp.arange(num_train_samples))\n",
        "model_inputs = batch_from_indices(train_data, train_samples_idx[:train_batch_size])\n",
        "model_inputs = flax.training.common_utils.shard(model_inputs)\n",
        "state, train_metric, dropout_rngs = p_train_step(state, model_inputs, dropout_rng=dropout_rngs)\n",
        "train_metric = flax.jax_utils.unreplicate(train_metric)\n",
        "print('Done.  First loss was', train_metric['loss'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doKKw-W345Zn",
        "outputId": "a8917838-c91d-4759-cf88-159223fd6abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch ... :   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Training...:   0%|          | 0/1178 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [02:51<?, ?it/s]\n",
            "Training...:   0%|          | 1/1178 [02:51<27:40:53, 84.67s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.415671348571777, Learning Rate: 0.00029974535573273897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [04:21<?, ?it/s]\n",
            "Training...:   0%|          | 2/1178 [04:21<28:39:30, 87.73s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.754929542541504, Learning Rate: 0.0002996179973706603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [05:53<?, ?it/s]\n",
            "Training...:   0%|          | 3/1178 [05:53<29:25:41, 90.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.138077735900879, Learning Rate: 0.0002994906681124121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [07:21<?, ?it/s]\n",
            "Training...:   0%|          | 4/1178 [07:21<29:14:10, 89.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.438237190246582, Learning Rate: 0.0002993633388541639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [08:52<?, ?it/s]\n",
            "Training...:   0%|          | 5/1178 [08:52<29:25:20, 90.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.3292617797851562, Learning Rate: 0.0002992360095959157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [10:21<?, ?it/s]\n",
            "Training...:   1%|          | 6/1178 [10:21<29:09:45, 89.58s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.124711513519287, Learning Rate: 0.00029910868033766747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [11:52<?, ?it/s]\n",
            "Training...:   1%|          | 7/1178 [11:52<29:22:08, 90.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.276705265045166, Learning Rate: 0.00029898135107941926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [13:20<?, ?it/s]\n",
            "Training...:   1%|          | 8/1178 [13:20<29:07:37, 89.62s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.4579017162323, Learning Rate: 0.0002988539927173406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [14:53<?, ?it/s]\n",
            "Training...:   1%|          | 9/1178 [14:53<29:23:33, 90.52s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.7165687084198, Learning Rate: 0.0002987266634590924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [16:20<?, ?it/s]\n",
            "Training...:   1%|          | 10/1178 [16:20<29:05:57, 89.69s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.503625392913818, Learning Rate: 0.00029859933420084417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [17:50<?, ?it/s]\n",
            "Training...:   1%|          | 11/1178 [17:49<29:05:02, 89.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.152625560760498, Learning Rate: 0.00029847200494259596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [19:16<?, ?it/s]\n",
            "Training...:   1%|          | 12/1178 [19:16<28:48:27, 88.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.3537991046905518, Learning Rate: 0.00029834467568434775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [20:46<?, ?it/s]\n",
            "Training...:   1%|          | 13/1178 [20:46<28:52:46, 89.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.2029027938842773, Learning Rate: 0.0002982173173222691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [22:13<?, ?it/s]\n",
            "Training...:   1%|          | 14/1178 [22:13<28:37:18, 88.52s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.3617732524871826, Learning Rate: 0.00029808998806402087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [23:43<?, ?it/s]\n",
            "Training...:   1%|▏         | 15/1178 [23:43<28:43:22, 88.91s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.775648832321167, Learning Rate: 0.00029796265880577266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [25:11<?, ?it/s]\n",
            "Training...:   1%|▏         | 16/1178 [25:11<28:31:35, 88.38s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7661454677581787, Learning Rate: 0.00029783532954752445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [26:42<?, ?it/s]\n",
            "Training...:   1%|▏         | 17/1178 [26:42<28:45:44, 89.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.958035945892334, Learning Rate: 0.00029770800028927624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [28:09<?, ?it/s]\n",
            "Training...:   2%|▏         | 18/1178 [28:09<28:34:21, 88.67s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.146214485168457, Learning Rate: 0.00029758067103102803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [29:39<?, ?it/s]\n",
            "Training...:   2%|▏         | 19/1178 [29:39<28:42:01, 89.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.4021518230438232, Learning Rate: 0.00029745331266894937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [31:06<?, ?it/s]\n",
            "Training...:   2%|▏         | 20/1178 [31:06<28:28:15, 88.51s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.3667867183685303, Learning Rate: 0.00029732598341070116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [32:35<?, ?it/s]\n",
            "Training...:   2%|▏         | 21/1178 [32:35<28:34:14, 88.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.639209508895874, Learning Rate: 0.00029719865415245295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [34:02<?, ?it/s]\n",
            "Training...:   2%|▏         | 22/1178 [34:02<28:17:52, 88.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.927880048751831, Learning Rate: 0.00029707132489420474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [35:32<?, ?it/s]\n",
            "Training...:   2%|▏         | 23/1178 [35:32<28:25:58, 88.62s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.953857898712158, Learning Rate: 0.0002969439956359565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [36:59<?, ?it/s]\n",
            "Training...:   2%|▏         | 24/1178 [36:59<28:18:12, 88.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.8662846088409424, Learning Rate: 0.0002968166663777083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [38:28<?, ?it/s]\n",
            "Training...:   2%|▏         | 25/1178 [38:28<28:21:18, 88.53s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.884594202041626, Learning Rate: 0.00029668930801562965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [39:55<?, ?it/s]\n",
            "Training...:   2%|▏         | 26/1178 [39:55<28:10:08, 88.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5779452323913574, Learning Rate: 0.00029656197875738144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [41:24<?, ?it/s]\n",
            "Training...:   2%|▏         | 27/1178 [41:23<28:11:14, 88.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.6711177825927734, Learning Rate: 0.00029643464949913323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [42:50<?, ?it/s]\n",
            "Training...:   2%|▏         | 28/1178 [42:50<28:01:31, 87.73s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.4810945987701416, Learning Rate: 0.000296307320240885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [44:19<?, ?it/s]\n",
            "Training...:   2%|▏         | 29/1178 [44:19<28:10:44, 88.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.9048943519592285, Learning Rate: 0.0002961799909826368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [45:46<?, ?it/s]\n",
            "Training...:   3%|▎         | 30/1178 [45:46<27:56:47, 87.64s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7232892513275146, Learning Rate: 0.00029605263262055814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [47:17<?, ?it/s]\n",
            "Training...:   3%|▎         | 31/1178 [47:17<28:06:32, 88.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.332340955734253, Learning Rate: 0.00029592530336230993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [48:42<?, ?it/s]\n",
            "Training...:   3%|▎         | 32/1178 [48:42<28:03:17, 88.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.019341230392456, Learning Rate: 0.0002957979741040617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [50:12<?, ?it/s]\n",
            "Training...:   3%|▎         | 33/1178 [50:12<28:07:39, 88.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.4316086769104004, Learning Rate: 0.0002956706448458135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [51:38<?, ?it/s]\n",
            "Training...:   3%|▎         | 34/1178 [51:38<27:52:49, 87.74s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.505936861038208, Learning Rate: 0.0002955433155875653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [53:05<?, ?it/s]\n",
            "Training...:   3%|▎         | 35/1178 [53:05<27:52:04, 87.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.3003008365631104, Learning Rate: 0.0002954159863293171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [54:31<?, ?it/s]\n",
            "Training...:   3%|▎         | 36/1178 [54:31<27:38:58, 87.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.0785036087036133, Learning Rate: 0.0002952886279672384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [56:00<?, ?it/s]\n",
            "Training...:   3%|▎         | 37/1178 [56:00<27:47:32, 87.69s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7013142108917236, Learning Rate: 0.0002951612987089902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [57:27<?, ?it/s]\n",
            "Training...:   3%|▎         | 38/1178 [57:27<27:40:00, 87.37s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5510644912719727, Learning Rate: 0.000295033969450742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [58:59<?, ?it/s]\n",
            "Training...:   3%|▎         | 39/1178 [58:59<27:45:32, 87.74s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.3703503608703613, Learning Rate: 0.0002949066401924938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:00:25<?, ?it/s]\n",
            "Training...:   3%|▎         | 40/1178 [1:00:25<27:54:03, 88.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.4108047485351562, Learning Rate: 0.0002947793109342456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:01:55<?, ?it/s]\n",
            "Training...:   3%|▎         | 41/1178 [1:01:55<28:00:02, 88.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7311525344848633, Learning Rate: 0.0002946519525721669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:03:21<?, ?it/s]\n",
            "Training...:   4%|▎         | 42/1178 [1:03:21<27:43:58, 87.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5849854946136475, Learning Rate: 0.0002945246233139187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:04:51<?, ?it/s]\n",
            "Training...:   4%|▎         | 43/1178 [1:04:51<27:54:49, 88.54s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5547797679901123, Learning Rate: 0.0002943972940556705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:06:17<?, ?it/s]\n",
            "Training...:   4%|▎         | 44/1178 [1:06:17<27:39:30, 87.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.866323709487915, Learning Rate: 0.0002942699647974223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:07:47<?, ?it/s]\n",
            "Training...:   4%|▍         | 45/1178 [1:07:47<27:46:33, 88.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.2122509479522705, Learning Rate: 0.0002941426355391741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:09:12<?, ?it/s]\n",
            "Training...:   4%|▍         | 46/1178 [1:09:12<27:33:57, 87.67s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.524303913116455, Learning Rate: 0.00029401530628092587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:10:41<?, ?it/s]\n",
            "Training...:   4%|▍         | 47/1178 [1:10:41<27:40:55, 88.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.4259281158447266, Learning Rate: 0.0002938879479188472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:12:08<?, ?it/s]\n",
            "Training...:   4%|▍         | 48/1178 [1:12:08<27:31:56, 87.71s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7158706188201904, Learning Rate: 0.000293760618660599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:13:38<?, ?it/s]\n",
            "Training...:   4%|▍         | 49/1178 [1:13:38<27:41:13, 88.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7530322074890137, Learning Rate: 0.0002936332894023508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:15:04<?, ?it/s]\n",
            "Training...:   4%|▍         | 50/1178 [1:15:04<27:25:10, 87.51s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.325739622116089, Learning Rate: 0.0002935059601441026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:16:33<?, ?it/s]\n",
            "Training...:   4%|▍         | 51/1178 [1:16:33<27:31:22, 87.92s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.83027184009552, Learning Rate: 0.00029337863088585436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:17:59<?, ?it/s]\n",
            "Training...:   4%|▍         | 52/1178 [1:17:59<27:20:42, 87.43s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.135831117630005, Learning Rate: 0.00029325130162760615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:19:29<?, ?it/s]\n",
            "Training...:   4%|▍         | 53/1178 [1:19:29<27:32:00, 88.11s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.2436935901641846, Learning Rate: 0.0002931239432655275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:20:59<?, ?it/s]\n",
            "Training...:   5%|▍         | 54/1178 [1:20:59<27:30:02, 88.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.229268789291382, Learning Rate: 0.0002929966140072793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:22:30<?, ?it/s]\n",
            "Training...:   5%|▍         | 55/1178 [1:22:30<27:58:17, 89.67s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7077348232269287, Learning Rate: 0.00029286928474903107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:23:57<?, ?it/s]\n",
            "Training...:   5%|▍         | 56/1178 [1:23:57<27:41:47, 88.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.3071975708007812, Learning Rate: 0.00029274195549078286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:25:29<?, ?it/s]\n",
            "Training...:   5%|▍         | 57/1178 [1:25:29<27:54:52, 89.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.9384005069732666, Learning Rate: 0.00029261462623253465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:26:55<?, ?it/s]\n",
            "Training...:   5%|▍         | 58/1178 [1:26:55<27:33:29, 88.58s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.189760446548462, Learning Rate: 0.000292487267870456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:28:24<?, ?it/s]\n",
            "Training...:   5%|▌         | 59/1178 [1:28:24<27:36:45, 88.83s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.6849722862243652, Learning Rate: 0.00029235993861220777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:29:51<?, ?it/s]\n",
            "Training...:   5%|▌         | 60/1178 [1:29:51<27:22:08, 88.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.0627479553222656, Learning Rate: 0.00029223260935395956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:31:20<?, ?it/s]\n",
            "Training...:   5%|▌         | 61/1178 [1:31:20<27:26:58, 88.47s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.858654260635376, Learning Rate: 0.00029210528009571135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:32:46<?, ?it/s]\n",
            "Training...:   5%|▌         | 62/1178 [1:32:46<27:13:09, 87.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.9708971977233887, Learning Rate: 0.00029197795083746314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:34:15<?, ?it/s]\n",
            "Training...:   5%|▌         | 63/1178 [1:34:15<27:19:14, 88.21s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.1576857566833496, Learning Rate: 0.00029185062157921493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:35:42<?, ?it/s]\n",
            "Training...:   5%|▌         | 64/1178 [1:35:42<27:08:29, 87.71s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.9060282707214355, Learning Rate: 0.00029172326321713626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:37:12<?, ?it/s]\n",
            "Training...:   6%|▌         | 65/1178 [1:37:12<27:23:01, 88.57s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.3166537284851074, Learning Rate: 0.00029159593395888805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:38:38<?, ?it/s]\n",
            "Training...:   6%|▌         | 66/1178 [1:38:38<27:07:08, 87.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.55352783203125, Learning Rate: 0.00029146860470063984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:40:06<?, ?it/s]\n",
            "Training...:   6%|▌         | 67/1178 [1:40:06<27:11:58, 88.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.4462223052978516, Learning Rate: 0.00029134127544239163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:41:32<?, ?it/s]\n",
            "Training...:   6%|▌         | 68/1178 [1:41:32<26:53:44, 87.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.8462040424346924, Learning Rate: 0.0002912139461841434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:43:02<?, ?it/s]\n",
            "Training...:   6%|▌         | 69/1178 [1:43:02<27:06:57, 88.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9085534811019897, Learning Rate: 0.00029108658782206476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:44:29<?, ?it/s]\n",
            "Training...:   6%|▌         | 70/1178 [1:44:29<26:53:06, 87.35s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.498732805252075, Learning Rate: 0.00029095925856381655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:46:00<?, ?it/s]\n",
            "Training...:   6%|▌         | 71/1178 [1:46:00<27:11:59, 88.46s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.010699987411499, Learning Rate: 0.00029083192930556834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:47:27<?, ?it/s]\n",
            "Training...:   6%|▌         | 72/1178 [1:47:27<27:02:42, 88.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.488053560256958, Learning Rate: 0.00029070460004732013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:48:58<?, ?it/s]\n",
            "Training...:   6%|▌         | 73/1178 [1:48:58<27:09:26, 88.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0326480865478516, Learning Rate: 0.0002905772707890719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:50:29<?, ?it/s]\n",
            "Training...:   6%|▋         | 74/1178 [1:50:29<27:15:26, 88.88s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.519871473312378, Learning Rate: 0.0002904499415308237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:51:59<?, ?it/s]\n",
            "Training...:   6%|▋         | 75/1178 [1:51:59<27:39:40, 90.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.931639313697815, Learning Rate: 0.00029032258316874504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:53:25<?, ?it/s]\n",
            "Training...:   6%|▋         | 76/1178 [1:53:25<27:15:37, 89.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1518547534942627, Learning Rate: 0.00029019525391049683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:54:58<?, ?it/s]\n",
            "Training...:   7%|▋         | 77/1178 [1:54:58<27:22:49, 89.53s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.194817304611206, Learning Rate: 0.0002900679246522486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:56:25<?, ?it/s]\n",
            "Training...:   7%|▋         | 78/1178 [1:56:25<27:17:57, 89.34s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.260181427001953, Learning Rate: 0.0002899405953940004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:57:58<?, ?it/s]\n",
            "Training...:   7%|▋         | 79/1178 [1:57:58<27:37:28, 90.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1938014030456543, Learning Rate: 0.0002898132661357522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [1:59:26<?, ?it/s]\n",
            "Training...:   7%|▋         | 80/1178 [1:59:26<27:18:38, 89.54s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1845977306365967, Learning Rate: 0.00028968590777367353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:00:58<?, ?it/s]\n",
            "Training...:   7%|▋         | 81/1178 [2:00:58<27:29:03, 90.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0740139484405518, Learning Rate: 0.0002895585785154253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:02:26<?, ?it/s]\n",
            "Training...:   7%|▋         | 82/1178 [2:02:26<27:14:13, 89.46s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.3197999000549316, Learning Rate: 0.0002894312492571771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:03:55<?, ?it/s]\n",
            "Training...:   7%|▋         | 83/1178 [2:03:55<27:17:08, 89.71s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.799525499343872, Learning Rate: 0.0002893039199989289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:05:21<?, ?it/s]\n",
            "Training...:   7%|▋         | 84/1178 [2:05:21<26:57:43, 88.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.8576619625091553, Learning Rate: 0.0002891765907406807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:06:52<?, ?it/s]\n",
            "Training...:   7%|▋         | 85/1178 [2:06:52<27:06:12, 89.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0377752780914307, Learning Rate: 0.0002890492614824325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:08:19<?, ?it/s]\n",
            "Training...:   7%|▋         | 86/1178 [2:08:19<26:50:39, 88.50s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0669028759002686, Learning Rate: 0.0002889219031203538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:09:49<?, ?it/s]\n",
            "Training...:   7%|▋         | 87/1178 [2:09:49<26:54:34, 88.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1075186729431152, Learning Rate: 0.0002887945738621056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:11:17<?, ?it/s]\n",
            "Training...:   7%|▋         | 88/1178 [2:11:17<26:50:34, 88.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.060795783996582, Learning Rate: 0.0002886672446038574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:12:49<?, ?it/s]\n",
            "Training...:   8%|▊         | 89/1178 [2:12:49<27:06:24, 89.61s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.8514342308044434, Learning Rate: 0.0002885399153456092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:14:16<?, ?it/s]\n",
            "Training...:   8%|▊         | 90/1178 [2:14:16<26:52:38, 88.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.079394578933716, Learning Rate: 0.000288412586087361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:15:47<?, ?it/s]\n",
            "Training...:   8%|▊         | 91/1178 [2:15:47<26:55:59, 89.20s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.755836248397827, Learning Rate: 0.00028828525682911277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:17:14<?, ?it/s]\n",
            "Training...:   8%|▊         | 92/1178 [2:17:14<26:45:00, 88.67s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.349865198135376, Learning Rate: 0.0002881578984670341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:18:45<?, ?it/s]\n",
            "Training...:   8%|▊         | 93/1178 [2:18:45<26:54:42, 89.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.065974235534668, Learning Rate: 0.0002880305692087859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:20:13<?, ?it/s]\n",
            "Training...:   8%|▊         | 94/1178 [2:20:13<26:47:58, 89.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.833448052406311, Learning Rate: 0.0002879032399505377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:21:44<?, ?it/s]\n",
            "Training...:   8%|▊         | 95/1178 [2:21:44<26:58:18, 89.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.7469723224639893, Learning Rate: 0.00028777591069228947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:23:12<?, ?it/s]\n",
            "Training...:   8%|▊         | 96/1178 [2:23:12<26:44:52, 89.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.2243869304656982, Learning Rate: 0.00028764858143404126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:24:43<?, ?it/s]\n",
            "Training...:   8%|▊         | 97/1178 [2:24:43<26:52:59, 89.53s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.2368345260620117, Learning Rate: 0.0002875212230719626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:26:10<?, ?it/s]\n",
            "Training...:   8%|▊         | 98/1178 [2:26:10<26:41:11, 88.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9833900928497314, Learning Rate: 0.0002873938938137144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:27:41<?, ?it/s]\n",
            "Training...:   8%|▊         | 99/1178 [2:27:41<26:53:56, 89.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.8170106410980225, Learning Rate: 0.0002872665645554662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:29:08<?, ?it/s]\n",
            "Training...:   8%|▊         | 100/1178 [2:29:08<26:35:03, 88.78s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.049165725708008, Learning Rate: 0.00028713923529721797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:30:38<?, ?it/s]\n",
            "Training...:   9%|▊         | 101/1178 [2:30:38<26:40:48, 89.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.9288742542266846, Learning Rate: 0.00028701190603896976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:32:06<?, ?it/s]\n",
            "Training...:   9%|▊         | 102/1178 [2:32:06<26:32:38, 88.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.051964044570923, Learning Rate: 0.00028688457678072155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:33:37<?, ?it/s]\n",
            "Training...:   9%|▊         | 103/1178 [2:33:37<26:45:03, 89.58s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9110952615737915, Learning Rate: 0.0002867572184186429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:35:05<?, ?it/s]\n",
            "Training...:   9%|▉         | 104/1178 [2:35:05<26:33:06, 89.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.2376902103424072, Learning Rate: 0.00028662988916039467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:36:36<?, ?it/s]\n",
            "Training...:   9%|▉         | 105/1178 [2:36:36<26:43:40, 89.67s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.672438621520996, Learning Rate: 0.00028650255990214646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:38:02<?, ?it/s]\n",
            "Training...:   9%|▉         | 106/1178 [2:38:02<26:24:02, 88.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.126004934310913, Learning Rate: 0.00028637523064389825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:39:32<?, ?it/s]\n",
            "Training...:   9%|▉         | 107/1178 [2:39:32<26:27:55, 88.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.5540645122528076, Learning Rate: 0.00028624790138565004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:40:59<?, ?it/s]\n",
            "Training...:   9%|▉         | 108/1178 [2:40:59<26:17:31, 88.46s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.3682210445404053, Learning Rate: 0.00028612054302357137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:42:30<?, ?it/s]\n",
            "Training...:   9%|▉         | 109/1178 [2:42:30<26:29:53, 89.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1038522720336914, Learning Rate: 0.00028599321376532316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:43:58<?, ?it/s]\n",
            "Training...:   9%|▉         | 110/1178 [2:43:58<26:20:23, 88.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.035813331604004, Learning Rate: 0.00028586588450707495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:45:29<?, ?it/s]\n",
            "Training...:   9%|▉         | 111/1178 [2:45:29<26:26:55, 89.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.511983871459961, Learning Rate: 0.00028573855524882674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:46:56<?, ?it/s]\n",
            "Training...:  10%|▉         | 112/1178 [2:46:56<26:14:36, 88.63s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.265326499938965, Learning Rate: 0.00028561122599057853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:48:26<?, ?it/s]\n",
            "Training...:  10%|▉         | 113/1178 [2:48:26<26:20:58, 89.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.9656460285186768, Learning Rate: 0.0002854838967323303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:49:54<?, ?it/s]\n",
            "Training...:  10%|▉         | 114/1178 [2:49:54<26:15:37, 88.85s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.7086155414581299, Learning Rate: 0.00028535653837025166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:51:24<?, ?it/s]\n",
            "Training...:  10%|▉         | 115/1178 [2:51:24<26:18:10, 89.08s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.432464838027954, Learning Rate: 0.00028522920911200345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:52:52<?, ?it/s]\n",
            "Training...:  10%|▉         | 116/1178 [2:52:52<26:11:51, 88.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1233954429626465, Learning Rate: 0.00028510187985375524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:54:24<?, ?it/s]\n",
            "Training...:  10%|▉         | 117/1178 [2:54:24<26:26:36, 89.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9151486158370972, Learning Rate: 0.000284974550595507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:55:50<?, ?it/s]\n",
            "Training...:  10%|█         | 118/1178 [2:55:50<26:09:04, 88.82s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.6430037021636963, Learning Rate: 0.0002848472213372588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:57:21<?, ?it/s]\n",
            "Training...:  10%|█         | 119/1178 [2:57:21<26:14:51, 89.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9636842012405396, Learning Rate: 0.00028471986297518015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [2:58:48<?, ?it/s]\n",
            "Training...:  10%|█         | 120/1178 [2:58:48<26:02:14, 88.60s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.081475257873535, Learning Rate: 0.00028459253371693194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:00:19<?, ?it/s]\n",
            "Training...:  10%|█         | 121/1178 [3:00:19<26:14:17, 89.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9105335474014282, Learning Rate: 0.00028446520445868373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:01:47<?, ?it/s]\n",
            "Training...:  10%|█         | 122/1178 [3:01:47<26:02:40, 88.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.048203945159912, Learning Rate: 0.0002843378752004355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:03:19<?, ?it/s]\n",
            "Training...:  10%|█         | 123/1178 [3:03:19<26:14:31, 89.55s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9994018077850342, Learning Rate: 0.0002842105459421873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:04:45<?, ?it/s]\n",
            "Training...:  11%|█         | 124/1178 [3:04:45<26:03:26, 89.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.477750062942505, Learning Rate: 0.0002840832166839391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:06:17<?, ?it/s]\n",
            "Training...:  11%|█         | 125/1178 [3:06:17<26:15:43, 89.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0238077640533447, Learning Rate: 0.00028395585832186043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:07:45<?, ?it/s]\n",
            "Training...:  11%|█         | 126/1178 [3:07:45<26:06:16, 89.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.309656858444214, Learning Rate: 0.0002838285290636122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:09:19<?, ?it/s]\n",
            "Training...:  11%|█         | 127/1178 [3:09:19<26:17:28, 90.06s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.725183367729187, Learning Rate: 0.000283701199805364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:10:46<?, ?it/s]\n",
            "Training...:  11%|█         | 128/1178 [3:10:46<26:13:45, 89.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.4328112602233887, Learning Rate: 0.0002835738705471158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:12:20<?, ?it/s]\n",
            "Training...:  11%|█         | 129/1178 [3:12:20<26:19:57, 90.37s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.9654161930084229, Learning Rate: 0.0002834465412888676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:13:48<?, ?it/s]\n",
            "Training...:  11%|█         | 130/1178 [3:13:48<26:09:14, 89.84s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.806567430496216, Learning Rate: 0.0002833192120306194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:15:21<?, ?it/s]\n",
            "Training...:  11%|█         | 131/1178 [3:15:21<26:27:46, 90.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0135629177093506, Learning Rate: 0.0002831918536685407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:16:48<?, ?it/s]\n",
            "Training...:  11%|█         | 132/1178 [3:16:48<26:05:55, 89.82s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.8050811290740967, Learning Rate: 0.0002830645244102925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:18:21<?, ?it/s]\n",
            "Training...:  11%|█▏        | 133/1178 [3:18:21<26:20:16, 90.73s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.4847710132598877, Learning Rate: 0.0002829371951520443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:19:53<?, ?it/s]\n",
            "Training...:  11%|█▏        | 134/1178 [3:19:53<26:06:10, 90.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.0961451530456543, Learning Rate: 0.0002828098658937961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:21:27<?, ?it/s]\n",
            "Training...:  11%|█▏        | 135/1178 [3:21:27<26:35:53, 91.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.8623870611190796, Learning Rate: 0.0002826825366355479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:22:59<?, ?it/s]\n",
            "Training...:  12%|█▏        | 136/1178 [3:22:59<26:25:02, 91.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.5315260887145996, Learning Rate: 0.0002825551782734692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:24:33<?, ?it/s]\n",
            "Training...:  12%|█▏        | 137/1178 [3:24:33<26:48:59, 92.74s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.623967170715332, Learning Rate: 0.000282427849015221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Epoch ... :   0%|          | 0/2 [3:26:02<?, ?it/s]\n",
            "Training...:  12%|█▏        | 138/1178 [3:26:02<26:29:52, 91.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.1767661571502686, Learning Rate: 0.0002823005197569728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training...:  12%|█▏        | 139/1178 [3:26:10<26:35:02, 92.11s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "train_time = 0\n",
        "epochs = tqdm.tqdm(range(num_epochs), desc=\"Epoch ... \", position=0)\n",
        "for epoch in epochs:\n",
        "    # ======================== Training ================================\n",
        "    train_start = time.time()\n",
        "    train_metrics = []\n",
        "\n",
        "    # Create sampling rng\n",
        "    rng, input_rng = jax.random.split(rng)\n",
        "\n",
        "    # Generate an epoch by shuffling sampling indices from the train dataset\n",
        "    num_train_samples = len(train_data['input_ids'])\n",
        "    train_samples_idx = jax.random.permutation(input_rng, jnp.arange(num_train_samples))\n",
        "    #train_batch_idx = generate_batch_splits(train_samples_idx, train_batch_size)\n",
        "\n",
        "    # Gather the indexes for creating the batch and do a training step\n",
        "    batches_tqdm = tqdm.tqdm(range(num_train_samples // train_batch_size), desc=\"Training...\", position=1)\n",
        "    for step, batch_idx in enumerate(batches_tqdm):\n",
        "        #samples = [tokenized_datasets[\"train\"][int(idx)] for idx in batch_idx]\n",
        "        model_inputs = batch_from_indices(train_data, train_samples_idx[train_batch_size * batch_idx:train_batch_size * batch_idx + train_batch_size])\n",
        "        #print('model_inputs are', {key:val.shape for key, val in model_inputs.items()})\n",
        "        #model_inputs = data_collator(samples)\n",
        "\n",
        "        # Model forward\n",
        "        model_inputs = flax.training.common_utils.shard(model_inputs)\n",
        "        state, train_metric, dropout_rngs = p_train_step(state, model_inputs, dropout_rng=dropout_rngs)\n",
        "        train_metrics.append(train_metric)\n",
        "\n",
        "        cur_step = epoch * (num_train_samples // train_batch_size) + step\n",
        "\n",
        "        if cur_step % logging_steps == 0 and cur_step > 0 and jax.process_index() == 0:\n",
        "            # Save metrics\n",
        "            train_metric = flax.jax_utils.unreplicate(train_metric)\n",
        "            train_time += time.time() - train_start\n",
        "            #if has_tensorboard and jax.process_index() == 0:\n",
        "            #    write_train_metric(summary_writer, train_metrics, train_time, cur_step)\n",
        "\n",
        "            epochs.write(\n",
        "                f\"Loss: {train_metric['loss'].mean()}, Learning Rate: {train_metric['learning_rate'].mean()}\"\n",
        "            )\n",
        "\n",
        "            train_metrics = []\n",
        "        #if cur_step % (num_train_samples // 8) == 0:\n",
        "            # save checkpoint\n",
        "            if jax.process_index() == 0:\n",
        "                params = jax.device_get(jax.tree_map(lambda x: x[0], state.params))\n",
        "                model.save_pretrained('local_model', params=params)\n",
        "                # repo.push_to_hub(commit_message=f'commit-message', blocking=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGdYRKVJxHxN"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  print(repr(eval(input('>>> '), globals(), locals())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2lLdDyZP0mT"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "machine_shape": "hm",
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}